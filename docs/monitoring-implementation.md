# Codeflow CLI Monitoring Implementation Guide

## Overview

This guide provides detailed implementation instructions for the comprehensive monitoring and alerting strategy designed for the Codeflow CLI application. The monitoring system includes metrics collection, structured logging, health checks, and alerting rules for production deployment.

## Architecture Components

### 1. Metrics Collection (`src/monitoring/metrics.ts`)

The metrics collector captures application performance data and sends it to CloudWatch.

#### Key Features:

- **Command Execution Metrics**: Track CLI command performance and success rates
- **Agent Metrics**: Monitor AI agent spawn times and execution performance
- **MCP Metrics**: Track Model Context Protocol operations
- **Memory Usage**: Monitor heap usage and garbage collection
- **File Operations**: Track I/O performance for sync and conversion operations

#### Usage Example:

```typescript
import { metrics } from '../monitoring/metrics';

// Record command execution
metrics.recordCommandExecution({
  command: 'setup',
  executionTime: 1250,
  success: true,
  agentCount: 3,
  fileCount: 15,
});

// Record agent performance
metrics.recordAgentExecution({
  agentName: 'codebase-analyzer',
  spawnTime: 150,
  executionTime: 2100,
  success: true,
  taskType: 'analysis',
});

// Flush metrics to CloudWatch
await metrics.flush();
```

### 2. Structured Logging (`src/monitoring/logger.ts`)

Winston-based logging with structured JSON output and multiple log levels.

#### Log Categories:

- **Command Logs**: Track CLI command execution with performance metrics
- **Agent Logs**: Monitor AI agent lifecycle and performance
- **MCP Logs**: Track Model Context Protocol operations
- **Performance Logs**: Dedicated logging for timing analysis
- **Health Logs**: System health check results

#### Usage Example:

```typescript
import { logCommand, logAgent, logPerformance } from '../monitoring/logger';

// Log command execution
const requestId = logCommand.start('setup', { projectPath: '/path/to/project' });
try {
  // Execute command
  const result = await setup(projectPath);
  logCommand.success(requestId, 'setup', 1250, { agentCount: 3 });
} catch (error) {
  logCommand.error(requestId, 'setup', error, 1250);
}

// Log performance warnings
if (executionTime > 30000) {
  logPerformance.slow('command-execution', executionTime, 30000, {
    command: 'research',
  });
}
```

### 3. Health Checks (`src/monitoring/health.ts`)

Comprehensive health checking system for all application components.

#### Health Checks Included:

- **Agent Registry**: Validates agent directory structure and accessibility
- **Command Loader**: Checks command file availability
- **File System**: Tests basic I/O operations
- **Memory**: Monitors heap usage and alerts on high consumption
- **MCP Server**: Validates MCP server connectivity (future implementation)

#### CLI Integration:

```bash
# Run health checks
codeflow health-check

# Output example:
🏥 Running Codeflow health checks...

📊 Overall Status: HEALTHY
⏱️  Uptime: 3600s
📦 Version: 0.12.12

🔍 Check Results:
  ✅ agentRegistry: HEALTHY
    Agent registry accessible
    Duration: 45ms

  ✅ commandLoader: HEALTHY
    Command loader accessible
    Duration: 23ms

  ✅ fileSystem: HEALTHY
    File system operations working
    Duration: 12ms

  ✅ memory: HEALTHY
    Memory usage normal: 145.3MB heap used
    Duration: 5ms
```

### 4. Alerting System (`src/monitoring/alerts.ts`)

Intelligent alerting with multiple notification channels and escalation policies.

#### Alert Rules:

- **Critical**: Command error rates > 5%, execution times > 30s
- **Warning**: Memory usage > 400MB, agent failures > 10%
- **Info**: MCP operation delays, performance trends

#### Supported Channels:

- **AWS SNS**: Email and SMS notifications
- **Slack**: Real-time team notifications
- **PagerDuty**: Incident management integration

## Infrastructure Setup

### AWS CloudWatch Configuration

The Terraform configuration in `infrastructure/aws-webapp/modules/monitoring/` provides:

#### CloudWatch Alarms:

```terraform
# ECS Performance Alarms
resource "aws_cloudwatch_metric_alarm" "ecs_cpu_high" {
  alarm_name          = "codeflow-${var.environment}-ecs-cpu-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/ECS"
  period              = "300"
  statistic           = "Average"
  threshold           = "80"
  alarm_actions       = [aws_sns_topic.alerts.arn]
}

# Application Performance Alarms
resource "aws_cloudwatch_metric_alarm" "codeflow_command_errors" {
  alarm_name          = "codeflow-${var.environment}-command-errors"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CommandSuccess"
  namespace           = "Codeflow/CLI"
  period              = "300"
  statistic           = "Average"
  threshold           = "0.95"
  alarm_description   = "Codeflow command success rate is low"
  alarm_actions       = [aws_sns_topic.alerts.arn]
}
```

#### CloudWatch Dashboard:

The monitoring module creates a comprehensive dashboard with:

- ECS resource utilization graphs
- ALB request metrics and error rates
- Custom Codeflow performance metrics
- Error log insights
- Success rate trends

### Deployment Configuration

#### Environment Variables:

```bash
# AWS Configuration
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key

# Monitoring Configuration
LOG_LEVEL=info
CONSOLE_LOG_LEVEL=warn
ALERT_SNS_TOPIC_ARN=arn:aws:sns:us-east-1:123456789012:codeflow-alerts

# Health Check Configuration
HEALTH_CHECK_INTERVAL=300000  # 5 minutes
```

#### Docker Configuration:

```dockerfile
FROM node:18-alpine

# Install monitoring dependencies
RUN apk add --no-cache curl

# Set environment variables
ENV NODE_ENV=production
ENV LOG_LEVEL=info
ENV AWS_REGION=us-east-1

# Health check endpoint
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

# Application
COPY . /app
WORKDIR /app
RUN npm ci --only=production
CMD ["npm", "start"]
```

## Integration Points

### CLI Command Integration

The monitoring system integrates with existing CLI commands:

```typescript
// In src/cli/setup.ts
import { metrics, logCommand } from '../monitoring';

export async function setup(projectPath: string, options: any) {
  const requestId = logCommand.start('setup', { projectPath });

  try {
    const startTime = Date.now();

    // Execute setup logic
    await performSetup(projectPath, options);

    const executionTime = Date.now() - startTime;

    // Record metrics
    metrics.recordCommandExecution({
      command: 'setup',
      executionTime,
      success: true,
      fileCount: getFileCount(projectPath),
    });

    logCommand.success(requestId, 'setup', executionTime, {
      fileCount: getFileCount(projectPath),
    });
  } catch (error) {
    const executionTime = Date.now() - startTime;

    metrics.recordCommandExecution({
      command: 'setup',
      executionTime,
      success: false,
      errorType: error.constructor.name,
    });

    logCommand.error(requestId, 'setup', error, executionTime);
    throw error;
  }
}
```

### MCP Server Integration

```typescript
// In mcp/codeflow-server.mjs
import { metrics, logMCP } from '../monitoring';

server.registerTool(
  'research',
  {
    description: 'Execute research workflow',
  },
  async (args) => {
    const requestId = logMCP.operation('research', args);

    try {
      const startTime = Date.now();

      // Execute research logic
      const result = await executeResearch(args);

      const duration = Date.now() - startTime;

      metrics.recordMCPOperation({
        operation: 'tool_call',
        duration,
        success: true,
        agentCount: result.agentCount,
      });

      logMCP.success(requestId, 'research', duration, {
        agentCount: result.agentCount,
      });

      return result;
    } catch (error) {
      const duration = Date.now() - startTime;

      metrics.recordMCPOperation({
        operation: 'tool_call',
        duration,
        success: false,
      });

      logMCP.error(requestId, 'research', error, duration);
      throw error;
    }
  }
);
```

## Alert Escalation and Response

### Escalation Matrix

| Severity | Response Time | Channels          | Escalation       |
| -------- | ------------- | ----------------- | ---------------- |
| Critical | 0-15 minutes  | PagerDuty + Slack | On-call engineer |
| Warning  | 15-60 minutes | Slack + Email     | Engineering team |
| Info     | 1-4 hours     | Dashboard         | Scheduled review |

### Incident Response Process

1. **Alert Triggered** → Notification sent to primary channel
2. **Triage (5 minutes)** → Assess impact and severity
3. **Investigation (15 minutes)** → Check logs, metrics, and recent changes
4. **Mitigation (30 minutes)** → Implement temporary fix
5. **Resolution (2 hours)** → Deploy permanent solution
6. **Post-mortem (24 hours)** → Document incident and improvements

### Runbooks

#### High Error Rate Response:

1. Check CloudWatch logs for error patterns
2. Review recent deployments and configuration changes
3. Check agent registry integrity
4. Scale ECS service if needed
5. Restart MCP server if unresponsive

#### Performance Degradation Response:

1. Check CloudWatch metrics for resource utilization
2. Review application logs for bottlenecks
3. Check database connection pools (if applicable)
4. Implement caching or optimization fixes
5. Scale infrastructure if needed

## Cost Optimization

### CloudWatch Costs:

- **Metrics**: $0.30 per metric per month
- **Logs**: $0.50 per GB ingested
- **Alarms**: $0.10 per alarm per month
- **Dashboard**: No additional cost

### Optimization Strategies:

```terraform
# Optimize log retention
resource "aws_cloudwatch_log_group" "codeflow_logs" {
  retention_in_days = var.environment == "prod" ? 90 : 30
}

# Use metric filters to reduce log volume
resource "aws_cloudwatch_log_metric_filter" "error_count" {
  log_group_name = aws_cloudwatch_log_group.codeflow_logs.name
  metric_transformation {
    name      = "ErrorCount"
    namespace = "Codeflow/Logs"
    value     = "1"
  }
  pattern = "\"level\":\"ERROR\""
}
```

## Testing and Validation

### Monitoring Tests

```typescript
// tests/monitoring.test.ts
describe('Monitoring System', () => {
  it('should record command metrics', async () => {
    const metrics = new MetricsCollector();

    metrics.recordCommandExecution({
      command: 'test-command',
      executionTime: 1000,
      success: true,
    });

    // Verify metrics were recorded
    expect(metrics).toHaveRecordedMetric('CommandExecutionTime');
  });

  it('should perform health checks', async () => {
    const healthChecker = new HealthChecker();

    const result = await healthChecker.runCheck('fileSystem');

    expect(result.status).toBe('healthy');
    expect(result.duration).toBeGreaterThan(0);
  });

  it('should trigger alerts', async () => {
    const alertManager = new AlertManager();

    await alertManager.evaluateMetrics({
      commandSuccessRate: 0.9, // Below 95% threshold
    });

    expect(alertManager.getActiveAlerts()).toHaveLength(1);
  });
});
```

### Load Testing

```bash
# Load test monitoring system
for i in {1..100}; do
  codeflow health-check &
done
wait

# Check metrics in CloudWatch
aws cloudwatch get-metric-statistics \
  --namespace Codeflow/CLI \
  --metric-name CommandExecutionTime \
  --start-time 2024-01-01T00:00:00Z \
  --end-time 2024-01-02T00:00:00Z \
  --period 3600 \
  --statistics Average
```

## Production Deployment Checklist

### Pre-Deployment

- [ ] Configure AWS credentials and region
- [ ] Set up CloudWatch permissions
- [ ] Configure SNS topics for alerts
- [ ] Set up PagerDuty integration (optional)
- [ ] Configure Slack webhooks (optional)

### Deployment

- [ ] Deploy Terraform infrastructure
- [ ] Update application environment variables
- [ ] Configure health check endpoints
- [ ] Set up log aggregation
- [ ] Test alert notifications

### Post-Deployment

- [ ] Verify CloudWatch dashboard creation
- [ ] Test health check endpoints
- [ ] Validate alert triggers
- [ ] Monitor error rates and performance
- [ ] Set up on-call rotation

### Maintenance

- [ ] Regular log retention review
- [ ] Alert threshold tuning
- [ ] Cost monitoring and optimization
- [ ] Incident response drill exercises

## Troubleshooting

### Common Issues

#### Metrics Not Appearing in CloudWatch

```bash
# Check AWS credentials
aws sts get-caller-identity

# Verify CloudWatch permissions
aws cloudwatch list-metrics --namespace Codeflow/CLI

# Check application logs for errors
tail -f logs/error.log
```

#### Alerts Not Triggering

```bash
# Check alarm configuration
aws cloudwatch describe-alarms --alarm-names codeflow-prod-command-errors

# Verify SNS topic permissions
aws sns list-subscriptions-by-topic --topic-arn $SNS_TOPIC_ARN

# Test alert manually
aws cloudwatch set-alarm-state \
  --alarm-name codeflow-prod-command-errors \
  --state-value ALARM \
  --state-reason "Testing alert system"
```

#### High Memory Usage

```bash
# Check current memory usage
codeflow health-check | grep memory

# Review application logs
grep "Memory usage" logs/performance.log

# Check for memory leaks
# Implement heap snapshots in development
```

## Future Enhancements

### Advanced Features

- **Distributed Tracing**: Implement AWS X-Ray for request tracing
- **Anomaly Detection**: Use CloudWatch Anomaly Detection for automated alerts
- **Custom Dashboards**: Create environment-specific monitoring views
- **Log Analytics**: Implement CloudWatch Insights for advanced log analysis

### Scaling Considerations

- **Multi-region Deployment**: Cross-region metric aggregation
- **High Availability**: Redundant monitoring infrastructure
- **Custom Metrics**: Application-specific business metrics
- **Real-time Monitoring**: Implement WebSocket-based real-time dashboards

This implementation provides a production-ready monitoring solution that ensures Codeflow CLI maintains high availability, performance, and reliability across all deployment scenarios.
